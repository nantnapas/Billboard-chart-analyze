# -*- coding: utf-8 -*-
"""Copy of Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FVgWO7vwQCc0Y2YcrBu5aNNCKJF76uOa
"""

import requests
import urllib.request
from bs4 import BeautifulSoup
import csv
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib_venn import venn2

"""# Artist 100 chart 2019

ทำการ request ไปที่ url  ซึ่งใช้ Python library ที่ชื่อว่า request โดย lib ตัวนี้จะทำการ GET request ไปที่ web server ของ url ที่เราระบุ และจะทำการ download content ของ web page มาให้ และจากนั้น BeautifulSoup ทำการ parse content ที่เรา download ได้มา ให้มันสวยงามเข้าใจได้ง่าย
"""

url19 = "https://www.billboard.com/charts/artist-100/2019-09-28?fbclid=IwAR1ln03GaDLPonUxEPU42-mv3d5A89Vvl1zMrxKbKhC8kh_mpvqP8Q76lwU"
res19 = requests.get(url19)
soup19 = BeautifulSoup(res19.text, "html.parser")

"""เพื่อที่จะเห็นโครงสร้างแท็กอย่างเป็นระเบียบชัดเจนจะใช้เมธอด .prettify() ซึ่งเราจะใช้ tag เพื่อระบุตำแหน่งของข้อมูลที่ต้องการในการดึงข้อมูลออกมา"""

print(soup19.prettify())

artist19 = soup19.find_all('div', {'class' : 'chart-list-item'})
print(len(artist19))

print(artist19[0].prettify())

artist19[0].find('span', {'class' : 'chart-list-item__title-text'}).text

"""สร้าง list ว่างขึ้น จากนั้นเลือกtagและชื่อclassของข้อมูลที่ต้องการเพื่อนำไปเก็บไว้ในตัวแปรและเพิ่มตัวแปรทั้งหมดที่ต้องการไปเก็บใน list และทำการตัดอักขระ \n\n ด้านหน้าและด้านหลัง"""

art19 = []
for i in artist19:
    name = i.find('span', {'class' : 'chart-list-item__title-text'}).text.strip('\n\n')
    last_w = i.find('div', {'class' : 'chart-list-item__last-week'}).text  
    two_w = i.find('div', {'class' : 'chart-list-item__stats-cell '}).text.lstrip('\n\n').rstrip('\nTWO WEEKS AGO\n')
    peak_pos = i.find('div', {'class' : 'chart-list-item__weeks-at-one'}).text
    w_on_chart = i.find('div', {'class' : 'chart-list-item__weeks-on-chart'}).text
    imprint = i.find('div', {'class', 'chart-list-item__people_data'}).text.rstrip('\n\n')
    art19.append([name, last_w, two_w, peak_pos, w_on_chart,imprint[28:]])

for i in art19:
    if i[0].startswith(' '):
        i[0] = i[0].lstrip(' ')

pd.options.display.max_colwidth = 0

"""สร้างตารางแสดงข้อมูลจากตัวแปร art19 โดยมีคอลัมน์ชื่อ name, last_week, two_week_ago, peak_position, weeks_on_chart, Imprint/Promotion Label """

df19 = pd.DataFrame(art19, columns = ['name', 'last_week', 'two_week_ago', 'peak_position', 'weeks_on_chart', 'Imprint/Promotion Label'])
df19

"""ทำการแทนที่ข้อมูลในคอลัมน์ last_week, two_week_ago, peak_position, weeks_on_chart จาก  -  เป็นค่า 0 เพื่อให้ข้อมูลมีความต่อเนื่องและสามารถนำไปคำนวณเชิงคณิตศาสตร์ได้

"""

df19['last_week'].replace({'-':'0'}, inplace = True)
df19['two_week_ago'].replace({'-':'0'}, inplace = True)
df19['peak_position'].replace({'-':'0'}, inplace = True)
df19['weeks_on_chart'].replace({'-':'0'}, inplace = True)

"""เปลี่ยนชนิดของข้อมูลที่เป็นตัวหนังสือจากคอลัมน์ last_week, two_week_ago, peak_position, weeks_on_chart เป็นข้อมูลชนิดจำนวนเต็ม"""

df19['last_week'] = pd.to_numeric(df19['last_week'])
df19['two_week_ago'] = pd.to_numeric(df19['two_week_ago'])
df19['peak_position'] = pd.to_numeric(df19['peak_position'])
df19['weeks_on_chart'] = pd.to_numeric(df19['weeks_on_chart'])

df19[['Imprint/Promotion Label 1', 'Imprint/Promotion Label 2']] = df19['Imprint/Promotion Label'].str.split("|", expand = True)
df19['Imprint/Promotion Label 2'] = df19['Imprint/Promotion Label 2'].fillna('-')
df19.drop('Imprint/Promotion Label', axis = 1, inplace = True)

df19

df19.to_csv('artist year 2019.csv', index = False)

"""# Artist 100 chart 2020

ทำการ request ไปที่ url  ซึ่งใช้ Python library ที่ชื่อว่า request โดย lib ตัวนี้จะทำการ GET request ไปที่ web server ของ url ที่เราระบุ และจะทำการ download content ของ web page มาให้ และจากนั้น BeautifulSoup ทำการ parse content ที่เรา download ได้มา ให้มันสวยงามเข้าใจได้ง่าย
"""

url20 = "https://www.billboard.com/charts/artist-100/2020-09-26?fbclid=IwAR1SORpZ8nzqRfQ2YGqUOy16k2QoC8j6Z4VHwQXg31jR0qQvh5QNqLWTvEE"
res20 = requests.get(url20)
soup20 = BeautifulSoup(res20.text, "html.parser")

"""เพื่อที่จะเห็นโครงสร้างแท็กอย่างเป็นระเบียบชัดเจนจะใช้เมธอด .prettify() ซึ่งเราจะใช้ tag เพื่อระบุตำแหน่งของข้อมูลที่ต้องการในการดึงข้อมูลออกมา"""

print(soup20.prettify())

soup20.title.string

artist20 = soup20.find_all('div', {'class' : 'chart-list-item'})
print(len(artist20))

print(artist20[0].prettify())

artist20[0].find('span', {'class' : 'chart-list-item__title-text'}).text

"""สร้าง list ว่างขึ้น จากนั้นเลือกtagและชื่อclassของข้อมูลที่ต้องการเพื่อนำไปเก็บไว้ในตัวแปรและเพิ่มตัวแปรทั้งหมดที่ต้องการไปเก็บใน list และทำการตัดอักขระ \n\n ด้านหน้าและด้านหลัง"""

art20 = []
for i in artist20:
    name = i.find('span', {'class' : 'chart-list-item__title-text'}).text.strip('\n\n')
    last_w = i.find('div', {'class' : 'chart-list-item__last-week'}).text  
    two_w = i.find('div', {'class' : 'chart-list-item__stats-cell '}).text.lstrip('\n\n').rstrip('\nTWO WEEKS AGO\n')
    peak_pos = i.find('div', {'class' : 'chart-list-item__weeks-at-one'}).text
    w_on_chart = i.find('div', {'class' : 'chart-list-item__weeks-on-chart'}).text
    imprint = i.find('div', {'class', 'chart-list-item__people_data'}).text.rstrip('\n\n')
    art20.append([name, last_w, two_w, peak_pos, w_on_chart,imprint[28:]])

for i in art20:
    if i[0].startswith(' '):
        i[0] = i[0].lstrip(' ')

pd.options.display.max_colwidth = 0

"""สร้างตารางแสดงข้อมูลจากตัวแปร art20 โดยมีคอลัมน์ชื่อ name, last_week, two_week_ago, peak_position, weeks_on_chart, Imprint/Promotion Label """

df20 = pd.DataFrame(art20, columns = ['name', 'last_week', 'two_week_ago', 'peak_position', 'weeks_on_chart', 'Imprint/Promotion Label'])
df20

"""ทำการแทนที่ข้อมูลในคอลัมน์ last_week, two_week_ago, peak_position, weeks_on_chart จาก  -  เป็นค่า 0 เพื่อให้ข้อมูลมีความต่อเนื่องและสามารถนำไปคำนวณเชิงคณิตศาสตร์ได้"""

df20['last_week'].replace({'-':'0'}, inplace = True)
df20['two_week_ago'].replace({'-':'0'}, inplace = True)
df20['peak_position'].replace({'-':'0'}, inplace = True)
df20['weeks_on_chart'].replace({'-':'0'}, inplace = True)

"""เปลี่ยนชนิดของข้อมูลที่เป็นตัวหนังสือจากคอลัมน์ last_week, two_week_ago, peak_position, weeks_on_chart เป็นข้อมูลชนิดจำนวนเต็ม"""

df20['last_week'] = pd.to_numeric(df20['last_week'])
df20['two_week_ago'] = pd.to_numeric(df20['two_week_ago'])
df20['peak_position'] = pd.to_numeric(df20['peak_position'])
df20['weeks_on_chart'] = pd.to_numeric(df20['weeks_on_chart'])

df20[['Imprint/Promotion Label 1', 'Imprint/Promotion Label 2']] = df20['Imprint/Promotion Label'].str.split("|", expand = True)
df20['Imprint/Promotion Label 2'] = df20['Imprint/Promotion Label 2'].fillna('-')
df20.drop('Imprint/Promotion Label', axis = 1, inplace = True)

df20.head(20)

df20.to_csv('artist year 2020.csv', index = False)

"""# เปรียบเทียบอันดับ most popular

"""

import matplotlib.pyplot as plt

df19['rank'] = df19['weeks_on_chart'].rank(ascending=False, method='dense')
top19=df19.sort_values('rank').head(10).set_index('name')
top19

df20['rank'] = df20['weeks_on_chart'].rank(ascending=False, method='dense')
top20=df20.sort_values('rank').head(10).set_index('name')
top20

ax=top19['weeks_on_chart' ].plot(kind='barh', title='Most Popular 2019', color='paleturquoise', figsize=(10, 8));
ax.axvline(250, color = 'red', linestyle = '--', linewidth = 2)
ax.set_xlabel('weeks on chart', size = 25)
ax.set_ylabel('Name', size = 25)

"""**ศิลปินที่ติดอันดับ Weeks on chart ในปี 2019 เยอะที่สุดมี Maroon5 , Eminem และ Drake โดยทั้ง 3 มี Weeks on chart อยู่ที่ 273 เท่ากันและตามมาด้วย Taylor Swift และ Luke Bryan ตามลำดับ**"""

ax=top20['weeks_on_chart' ].plot(kind='barh', title='Most Popular 2020', color='plum', figsize=(10, 8));
ax.axvline(300, color = 'red', linestyle = '--', linewidth = 2)
ax.set_xlabel('weeks on chart', size = 25)
ax.set_ylabel('Name', size = 25)

"""**ใน 2020 ศิลปินที่ติดอันดับ Weeks on chart เป็นอันดับ 1 ยังเป็น Drake และ Maroon5 เหมือนปี 2019 แต่ Eminem ที่ติดอันดับ Weeks on chart เป็นอันดับ 1 ร่วมในปี 2019 ไม่ติด Top10 ในปี 2020**

# ส่วนที่ 2

สร้าง dataframe ของปี 2019
"""

df19['year'] = 2019
df19

data_1  = df19[['name', 'year']]
data_1

"""สร้าง dataframe ของปี 2020"""

df20['year'] = 2020
df20

data_2  = df20[['name', 'year']]
data_2

"""# ศิลปินที่ติด Billboard Chart ทั้งปี 2019 และ 2020

ทำการเชื่อม ทั้งสองปีเข้าด้วยกันโดยให้ปี 2019 เป็นหลักและทำการนำข้อมูลปี 2020 รวมเข้าด้วยกัน
"""

yearall = pd.merge(left=data_1,right=data_2, how='left', left_on='name', right_on='name')
yearall

yearall.rename(columns={"year_x": "year_2019", "year_y": "year_2020"})

"""ทำการตัดข้อมูลที่มีค่าเป็น NaN ออกเพื่อเอาข้อมูลศิลปินที่ติดอันดับทั้งสองปี และเรียงตามตัวอักษร"""

yearall.dropna(inplace=True)
yearall_s=yearall.sort_values('name')
yearall_s

yearall_s.index = np.arange(1, len(yearall) + 1)
yearall_s['name']

"""ศิลปินที่ติด Billboard Chart เฉพาะปี 2019

# ศิลปินที่ติด Billboard Chart เฉพาะปี 2019

ทำการรวมข้อมูลทั้งสองเข้าด้วยกันโดยใช้ปี 2019 เป็นหลัก
"""

year2019 = pd.merge(left=data_1,right=data_2, how='left', left_on='name', right_on='name')
year2019

"""ตัดข้อมูลที่มีปี 2020 ออก"""

new = year2019[year2019['year_y'] == 2020 ].index
year2019.drop(new, inplace=True)
year2019_s=year2019.sort_values('name')
year2019_s

year2019_s.index = np.arange(1, len(year2019) + 1)
year2019_s['name']

"""# ศิลปินที่ติด Billboard Chart เฉพาะปี 2020

ทำการรวมข้อมูลทั้งสองปี โดยเอาข้อมูลปี 2020 เป็นหลัก
"""

year2020 = pd.merge(left=data_2,right=data_1, how='left', left_on='name', right_on='name')
year2020

""" ตัดข้อมูลที่มีค่าเป็น 2019 ออกและทำการเรียงข้อมูลตามชื่อ"""

new2 = year2020[year2020['year_y'] == 2019 ].index
year2020.drop(new2, inplace=True)
year2020_s=year2020.sort_values('name')
year2020_s

year2020_s.index = np.arange(1, len(year2020) + 1)
year2020_s['name']

"""กราฟแสดงจำนวน Artist ในแต่ละปี"""

venn2(subsets = (51,51,49), set_labels = ('Yaer2019', 'Yaer2020'))
plt.title('Amount Of artist from Billbord 2019-2020')
plt.show()

